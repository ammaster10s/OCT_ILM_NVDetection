{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is in DATA_OCT\\dr_test_1190_NV.jpg\n",
    "# Mask data for evaluation is in Boom's ILM\\dr_test_1190_NV_ILM.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def preprocess_image(image_path, img_size=(640, 640)):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image at path {image_path} not found.\")\n",
    "\n",
    "    # Replace all white pixels (value > 250) with black\n",
    "    image[image > 250] = 0\n",
    "\n",
    "    # Detect and remove white borders\n",
    "    _, thresh = cv2.threshold(image, 240, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find all non-white pixels and get their coordinates\n",
    "    non_white_pixels = np.where(thresh < 240)\n",
    "\n",
    "    if non_white_pixels[0].size == 0 or non_white_pixels[1].size == 0:\n",
    "        raise ValueError(\"No relevant pixels found in the image.\")\n",
    "\n",
    "    # Get the smallest and largest x and y coordinates and use them to create the bounding box\n",
    "    y_min, y_max = np.min(non_white_pixels[0]), np.max(non_white_pixels[0])\n",
    "    x_min, x_max = np.min(non_white_pixels[1]), np.max(non_white_pixels[1])\n",
    "\n",
    "    # Crop the image to the bounding box of all non-white pixels\n",
    "    image = image[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    # Noise reduction using median blur, bilateral filter, and non-local means denoising\n",
    "    image_median = cv2.medianBlur(image, 5)\n",
    "    image_bilateral = cv2.bilateralFilter(image_median, 9, 75, 75)\n",
    "    image_denoised = cv2.fastNlMeansDenoising(image_bilateral, h=30)\n",
    "\n",
    "    # Wavelet denoising\n",
    "    coeffs = pywt.wavedec2(image_denoised, 'db1', level=2)\n",
    "    coeffs[1:] = [tuple(pywt.threshold(i, value=10, mode='soft') for i in level) for level in coeffs[1:]]\n",
    "    image_wavelet_denoised = pywt.waverec2(coeffs, 'db1')\n",
    "\n",
    "    # Resize the denoised image\n",
    "    image_resized = cv2.resize(image_wavelet_denoised, img_size)\n",
    "    image_resized = np.expand_dims(image_resized, axis=-1)\n",
    "    image_resized = np.expand_dims(image_resized, axis=0)\n",
    "    image_resized = image_resized.astype('float32') / 255.0\n",
    "\n",
    "    return image, image_resized\n",
    "\n",
    "def binary_mask(image):\n",
    "    # Convert the processed image to uint8\n",
    "    image_uint8 = (image * 255).astype(np.uint8).squeeze()\n",
    "\n",
    "    blurred_image = cv2.GaussianBlur(image_uint8, (5, 5), 0)\n",
    "    \n",
    "    # Apply binary thresholding\n",
    "    # _, binary_image = cv2.threshold(image_uint8, 62.5, 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    _, binary_image = cv2.threshold(blurred_image, 62.5, 255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    return binary_image\n",
    "\n",
    "def canny_edge_detection(image):\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return edges\n",
    "\n",
    "def extract_highest_y(edges):\n",
    "    height, width = edges.shape\n",
    "    highest_y_values = np.full(width, height)  # Initialize with maximum Y values (bottom of image)\n",
    "\n",
    "    for x in range(width):\n",
    "        column = edges[:, x]\n",
    "        y_indices = np.where(column > 0)[0]\n",
    "        if y_indices.size > 0:\n",
    "            highest_y = y_indices.min()  # Get the highest (minimum) Y value\n",
    "            highest_y_values[x] = highest_y  # Store the highest Y value\n",
    "\n",
    "    return highest_y_values\n",
    "\n",
    "def plot_highest_y_on_edges(edges, highest_y_values):\n",
    "    height, width = edges.shape\n",
    "    output_image = np.zeros_like(edges)\n",
    "\n",
    "    for x, y in enumerate(highest_y_values):\n",
    "        if y < height:  # Ensure we don't plot outside the image\n",
    "            output_image[y, x] = 255  # Plot highest Y values in white\n",
    "\n",
    "    return output_image\n",
    "\n",
    "def extract_top_line(highest_y_values):\n",
    "    # Create an image with the top line plotted\n",
    "    height = np.max(highest_y_values) + 1  # Ensure the image height is sufficient\n",
    "    width = len(highest_y_values)\n",
    "    top_line_image = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Draw the top line, making it bold\n",
    "    for x, y in enumerate(highest_y_values):\n",
    "        if y < height:  # Ensure we don't plot outside the image\n",
    "            cv2.line(top_line_image, (x, y), (x, y + 2), 255, 2)  # Plot bold line in white\n",
    "\n",
    "    return top_line_image\n",
    "\n",
    "def concatenate_paths(base_path, filenames):\n",
    "    return [os.path.join(base_path, filename) for filename in filenames]\n",
    "\n",
    "def process_and_visualize_images(image_paths):\n",
    "    for image_path in image_paths:\n",
    "        # Preprocess the image\n",
    "        original_image, preprocessed_image = preprocess_image(image_path)\n",
    "\n",
    "        # Apply binary masking\n",
    "        binary_image = binary_mask(preprocessed_image)\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        edges = canny_edge_detection(binary_image)\n",
    "\n",
    "        # Extract highest Y value edges\n",
    "        highest_y_values = extract_highest_y(edges)\n",
    "\n",
    "        # Plot highest Y values on the edges image\n",
    "        highest_y_image = plot_highest_y_on_edges(edges, highest_y_values)\n",
    "\n",
    "        # Extract and plot only the top line\n",
    "        top_line_image = extract_top_line(highest_y_values)\n",
    "\n",
    "        # Visualize the results\n",
    "        plt.figure(figsize=(25, 5))\n",
    "        plt.subplot(1, 5, 1)\n",
    "        plt.imshow(original_image, cmap='gray')\n",
    "        plt.title('Original Image')\n",
    "\n",
    "        plt.subplot(1, 5, 2)\n",
    "        plt.imshow(binary_image, cmap='gray')\n",
    "        plt.title('Binary Mask')\n",
    "\n",
    "        plt.subplot(1, 5, 3)\n",
    "        plt.imshow(edges, cmap='gray')\n",
    "        plt.title('Canny Edges')\n",
    "\n",
    "        plt.subplot(1, 5, 4)\n",
    "        plt.imshow(highest_y_image, cmap='gray')\n",
    "        plt.title('Highest Y Values')\n",
    "\n",
    "        plt.subplot(1, 5, 5)\n",
    "        plt.imshow(top_line_image, cmap='gray')\n",
    "        plt.title('Top Line')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "test_base_path = 'DATA_OCT'\n",
    "eval_base_path = 'BOOM_ILM'\n",
    "\n",
    "# Lists of filenames for test and evaluation datasets\n",
    "image_paths = ['dr_test_1190_NV.jpg', 'img_02.jpeg', 'img_04.jpeg',\n",
    "    'img_05.jpeg', 'img_06.jpeg', 'img_07.jpeg',\n",
    "    'img_08.jpeg', 'img_09 (1).jpeg', 'img_10.jpeg',\n",
    "    'img_11.jpeg', 'img_15.jpeg', 'img_16.jpeg', 'img_17.jpeg',\n",
    "    'img_18.jpeg', 'img_19.jpeg', 'img_21.jpeg',\n",
    "    'img_23.jpeg', 'img_24.jpeg', 'img_25.jpeg']\n",
    "\n",
    "eval_filenames = ['dr_test_1190_NV.jpg', 'img_02.jpeg', 'img_04.jpeg',\n",
    "    'img_05.jpeg', 'img_06.jpeg', 'img_07.jpeg',\n",
    "    'img_08.jpeg', 'img_09 (1).jpeg', 'img_10.jpeg',\n",
    "    'img_11.jpeg', 'img_15.jpeg', 'img_16.jpeg', 'img_17.jpeg',\n",
    "    'img_18.jpeg', 'img_19.jpeg', 'img_21.jpeg',\n",
    "    'img_23.jpeg', 'img_24.jpeg', 'img_25.jpeg']\n",
    "\n",
    "test_image_paths = concatenate_paths(test_base_path, image_paths)\n",
    "eval_image_paths = concatenate_paths(eval_base_path, eval_filenames)\n",
    "\n",
    "# Combine and process both test and evaluation image paths\n",
    "process_and_visualize_images(test_image_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Upgrade pip\n",
    "subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} python3.11.9 -m pip3 install --upgrade pip\n",
    "# !{sys.executable} -m pip install opencv-python\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "!{sys.executable} -m pip install PyWavelets\n",
    "# !{sys.executable} -m pip install scikit-learn\n",
    "# !{sys.executable} -m pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image at path {image_path} not found.\")\n",
    "\n",
    "    # Replace all white pixels (value > 250) with black\n",
    "    image[image > 250] = 0\n",
    "\n",
    "    # Detect and remove white borders\n",
    "    _, thresh = cv2.threshold(image, 240, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find all non-white pixels and get their coordinates\n",
    "    non_white_pixels = np.where(thresh < 240)\n",
    "\n",
    "    if non_white_pixels[0].size == 0 or non_white_pixels[1].size == 0:\n",
    "        raise ValueError(\"No relevant pixels found in the image.\")\n",
    "\n",
    "    # Get the smallest and largest x and y coordinates and use them to create the bounding box\n",
    "    y_min, y_max = np.min(non_white_pixels[0]), np.max(non_white_pixels[0])\n",
    "    x_min, x_max = np.min(non_white_pixels[1]), np.max(non_white_pixels[1])\n",
    "\n",
    "    # Crop the image to the bounding box of all non-white pixels\n",
    "    image = image[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    # Noise reduction using median blur, bilateral filter, and non-local means denoising\n",
    "    image_median = cv2.medianBlur(image, 5)\n",
    "    image_bilateral = cv2.bilateralFilter(image_median, 9, 75, 75)\n",
    "    image_denoised = cv2.fastNlMeansDenoising(image_bilateral, h=30)\n",
    "\n",
    "    # Wavelet denoising\n",
    "    coeffs = pywt.wavedec2(image_denoised, 'db1', level=2)\n",
    "    coeffs[1:] = [tuple(pywt.threshold(i, value=10, mode='soft') for i in level) for level in coeffs[1:]]\n",
    "    image_wavelet_denoised = pywt.waverec2(coeffs, 'db1')\n",
    "\n",
    "    # Normalize and expand dimensions\n",
    "    image_wavelet_denoised = np.expand_dims(image_wavelet_denoised, axis=-1)\n",
    "    image_wavelet_denoised = np.expand_dims(image_wavelet_denoised, axis=0)\n",
    "    image_wavelet_denoised = image_wavelet_denoised.astype('float32') / 255.0\n",
    "\n",
    "    return image, image_wavelet_denoised\n",
    "\n",
    "def binary_mask(image):\n",
    "    # Convert the processed image to uint8\n",
    "    image_uint8 = (image * 255).astype(np.uint8).squeeze()\n",
    "\n",
    "    # Apply Gaussian blur\n",
    "    blurred_image = cv2.GaussianBlur(image_uint8, (5, 5), 0)\n",
    "\n",
    "    # Apply binary thresholding with Otsu's method\n",
    "    _, binary_image = cv2.threshold(blurred_image, 62.5, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_image\n",
    "\n",
    "def canny_edge_detection(image):\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return edges\n",
    "\n",
    "def extract_highest_y(edges):\n",
    "    height, width = edges.shape\n",
    "    highest_y_values = np.full(width, height)  # Initialize with maximum Y values (bottom of image)\n",
    "\n",
    "    for x in range(width):\n",
    "        column = edges[:, x]\n",
    "        y_indices = np.where(column > 0)[0]\n",
    "        if y_indices.size > 0:\n",
    "            highest_y = y_indices.min()  # Get the highest (minimum) Y value\n",
    "            highest_y_values[x] = highest_y  # Store the highest Y value\n",
    "\n",
    "    return highest_y_values\n",
    "\n",
    "def plot_highest_y_on_edges(edges, highest_y_values):\n",
    "    height, width = edges.shape\n",
    "    output_image = np.zeros_like(edges)\n",
    "\n",
    "    for x, y in enumerate(highest_y_values):\n",
    "        if y < height:  # Ensure we don't plot outside the image\n",
    "            output_image[y, x] = 255  # Plot highest Y values in white\n",
    "\n",
    "    return output_image\n",
    "\n",
    "def extract_top_line(highest_y_values):\n",
    "    # Create an image with the top line plotted\n",
    "    height = np.max(highest_y_values) + 1  # Increase height to account for boldness\n",
    "    width = len(highest_y_values)\n",
    "    top_line_image = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Draw the top line, making it bolder\n",
    "    for x, y in enumerate(highest_y_values):\n",
    "        if y < height - 2:  # Ensure we don't plot outside the image\n",
    "            cv2.line(top_line_image, (x, y), (x, y + 2), 255, 2)  # Plot bold line in white\n",
    "\n",
    "    return top_line_image\n",
    "\n",
    "def concatenate_paths(base_path, filenames):\n",
    "    return [os.path.join(base_path, filename) for filename in filenames]\n",
    "\n",
    "def calculate_f1_score(ground_truth_image, predicted_image):\n",
    "    # Flatten the images to 1D arrays\n",
    "    ground_truth_flat = ground_truth_image.flatten()\n",
    "    predicted_flat = predicted_image.flatten()\n",
    "\n",
    "    # Create a mask for white pixels (value 255)\n",
    "    mask = ground_truth_flat == 255\n",
    "\n",
    "    # Calculate the F1 score using only the white pixels\n",
    "    f1 = f1_score(ground_truth_flat[mask], predicted_flat[mask], average='micro')\n",
    "\n",
    "    return f1\n",
    "\n",
    "def process_and_visualize_images(test_image_paths, eval_image_paths):\n",
    "    f1_scores = []\n",
    "\n",
    "    for test_image_path, eval_image_path in zip(test_image_paths, eval_image_paths):\n",
    "        # Preprocess the image\n",
    "        original_image, preprocessed_image = preprocess_image(test_image_path)\n",
    "\n",
    "        # Apply binary masking\n",
    "        binary_image = binary_mask(preprocessed_image)\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        edges = canny_edge_detection(binary_image)\n",
    "\n",
    "        # Extract highest Y value edges\n",
    "        highest_y_values = extract_highest_y(edges)\n",
    "\n",
    "        # Plot highest Y values on the edges image\n",
    "        highest_y_image = plot_highest_y_on_edges(edges, highest_y_values)\n",
    "\n",
    "        # Extract and plot only the top line\n",
    "        # Extract for evaluation\n",
    "        top_line_image = extract_top_line(highest_y_values)\n",
    "\n",
    "        # Load ground truth image\n",
    "        ground_truth_image = cv2.imread(eval_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if ground_truth_image is None:\n",
    "            raise FileNotFoundError(f\"Ground truth image at path {eval_image_path} not found.\")\n",
    "\n",
    "        # Resize The Picture incase of mismatch\n",
    "\n",
    "        if ground_truth_image.shape != top_line_image.shape:\n",
    "            # Resize predicted_image to match ground_truth_image\n",
    "            predicted_image = cv2.resize(top_line_image, \n",
    "                                         (ground_truth_image.shape[1], ground_truth_image.shape[0]))\n",
    "        else: \n",
    "            predicted_image = top_line_image\n",
    "\n",
    "        # Flatten the images\n",
    "        ground_truth_flat = ground_truth_image.flatten()\n",
    "        predicted_flat = predicted_image.flatten()\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = calculate_f1_score(ground_truth_flat, predicted_flat)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # plt.figure(figsize=(25, 5))\n",
    "        # plt.subplot(1, 5, 1)\n",
    "        # plt.imshow(original_image, cmap='gray')\n",
    "        # plt.title('Original Image')\n",
    "\n",
    "        # plt.subplot(1, 5, 2)\n",
    "        # plt.imshow(binary_image, cmap='gray')\n",
    "        # plt.title('Binary Mask')\n",
    "\n",
    "        # plt.subplot(1, 5, 3)\n",
    "        # plt.imshow(edges, cmap='gray')\n",
    "        # plt.title('Canny Edges')\n",
    "\n",
    "        # plt.subplot(1, 5, 4)\n",
    "        # plt.imshow(highest_y_image, cmap='gray')\n",
    "        # plt.title('Highest Y Values')\n",
    "\n",
    "        # plt.subplot(1, 5, 5)\n",
    "        # plt.imshow(top_line_image, cmap='gray')\n",
    "        # plt.title('Top Line')\n",
    "\n",
    "        # plt.show()\n",
    "        \n",
    "        \n",
    "\n",
    "    # Print the average F1 score\n",
    "    print(f\"Average F1 Score: {np.mean(f1_scores):.2f}\")\n",
    "\n",
    "# Example usage\n",
    "test_base_path = 'DATA_OCT'\n",
    "eval_base_path1 = 'BOOM_ILM'\n",
    "eval_base_path2 = 'Mighty_ILM1'\n",
    "\n",
    "# Lists of filenames for test and evaluation datasets\n",
    "test_filenames = [\n",
    "    'dr_test_1190_NV.jpg', 'img_02.jpeg', 'img_04.jpeg',\n",
    "    'img_05.jpeg', 'img_06.jpeg', 'img_07.jpeg',\n",
    "    'img_08.jpeg', 'img_09.jpeg', 'img_10.jpeg',\n",
    "    'img_11.jpeg', 'img_15.jpeg', 'img_16.jpeg',\n",
    "    'img_17.jpeg', 'img_18.jpeg', 'img_19.jpeg',\n",
    "    'img_21.jpeg', 'img_23.jpeg', 'img_24.jpeg',\n",
    "    'img_25.jpeg'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "eval_filenamesBoom = [\n",
    "    'dr_test_1190_NV.png', 'img_02.png', 'img_04.png',\n",
    "    'img_05.png', 'img_06.png', 'img_07.png',\n",
    "    'img_08.png', 'img_09 (1).PNG', 'img_10.png',\n",
    "    'img_11.png', 'img_15.png', 'img_16.png',\n",
    "    'img_17.png', 'img_18.png', 'img_19.png',\n",
    "    'img_21.png', 'img_23.png', 'img_24.png',\n",
    "    'img_25.png'\n",
    "]\n",
    "\n",
    "eval_filenamesMighty = [\n",
    "    'dr_test_1190_NV_ILM.png', 'img_02_ILM.png', 'img_04_ILM.png',\n",
    "    'img_05_ILM.png', 'img_06_ILM.png', 'img_07_ILM.png',\n",
    "    'img_08_ILM.png', 'img_09_ILM.png', 'img_10_ILM.png',\n",
    "    'img_11_ILM.png', 'img_15_ILM.png', 'img_16_ILM.png',\n",
    "    'img_17_ILM.png', 'img_18_ILM.png', 'img_19_ILM.png',\n",
    "    'img_21_ILM.png', 'img_23_ILM.png', 'img_24_ILM.png',\n",
    "    'img_25_ILM.png'\n",
    "]\n",
    "\n",
    "test_image_paths = concatenate_paths(test_base_path, test_filenames)\n",
    "eval_image_paths1 = concatenate_paths(eval_base_path1, eval_filenamesBoom)\n",
    "# eval_image_paths2 = concatenate_paths(eval_base_path2, eval_filenamesMighty)\n",
    "\n",
    "# Combine and process both test and evaluation image paths\n",
    "process_and_visualize_images(test_image_paths, eval_image_paths1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Foo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
