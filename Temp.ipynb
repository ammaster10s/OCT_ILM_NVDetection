{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import os\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def preprocess_image(image_path, img_size=(640, 640)):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image at path {image_path} not found.\")\n",
    "\n",
    "    # Replace all white pixels (value > 250) with black\n",
    "    image[image > 250] = 0\n",
    "\n",
    "    original_shape = image.shape\n",
    "\n",
    "    # Detect and remove white borders using Otsu's thresholding\n",
    "    _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Find all non-white pixels and get their coordinates\n",
    "    non_white_pixels = np.where(thresh < 255)\n",
    "\n",
    "    if non_white_pixels[0].size == 0 or non_white_pixels[1].size == 0:\n",
    "        raise ValueError(\"No relevant pixels found in the image.\")\n",
    "\n",
    "    # Get the smallest and largest x and y coordinates and use them to create the bounding box\n",
    "    y_min, y_max = np.min(non_white_pixels[0]), np.max(non_white_pixels[0])\n",
    "    x_min, x_max = np.min(non_white_pixels[1]), np.max(non_white_pixels[1])\n",
    "\n",
    "    # Crop the image to the bounding box of all non-white pixels\n",
    "    image = image[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    # Noise reduction using median blur, bilateral filter, and non-local means denoising\n",
    "    image_median = cv2.medianBlur(image, 5)\n",
    "    image_bilateral = cv2.bilateralFilter(image_median, 9, 75, 75)\n",
    "    image_denoised = cv2.fastNlMeansDenoising(image_bilateral, h=30)\n",
    "\n",
    "    # Wavelet denoising\n",
    "    coeffs = pywt.wavedec2(image_denoised, 'db1', level=2)\n",
    "    coeffs[1:] = [tuple(pywt.threshold(i, value=10, mode='soft') for i in level) for level in coeffs[1:]]\n",
    "    image_wavelet_denoised = pywt.waverec2(coeffs, 'db1')\n",
    "\n",
    "    # Resize the denoised image\n",
    "    image_resized = cv2.resize(image_wavelet_denoised, img_size)\n",
    "    image_resized = np.expand_dims(image_resized, axis=-1)\n",
    "    image_resized = np.expand_dims(image_resized, axis=0)\n",
    "    image_resized = image_resized.astype('float32') / 255.0\n",
    "\n",
    "    return image, image_resized, original_shape, (y_min, y_max, x_min, x_max)\n",
    "\n",
    "def binary_mask(image):\n",
    "    # Convert the processed image to uint8\n",
    "    image_uint8 = (image * 255).astype(np.uint8).squeeze()\n",
    "\n",
    "    # Apply Otsu's binary thresholding\n",
    "    _, binary_image = cv2.threshold(image_uint8, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_image\n",
    "\n",
    "def canny_edge_detection(image):\n",
    "    edges = cv2.Canny(image, 100, 200)\n",
    "    return edges\n",
    "\n",
    "def extract_highest_y(edges):\n",
    "    height, width = edges.shape\n",
    "    highest_y_values = np.full(width, height)  # Initialize with maximum Y values (bottom of image)\n",
    "\n",
    "    for x in range(width):\n",
    "        column = edges[:, x]\n",
    "        y_indices = np.where(column > 0)[0]\n",
    "        if y_indices.size > 0:\n",
    "            # Sort y_indices to find the highest (smallest) y value that's not 0\n",
    "            y_indices = np.sort(y_indices)\n",
    "            for y in y_indices:\n",
    "                if y != 0:\n",
    "                    highest_y_values[x] = y\n",
    "                    break\n",
    "            else:\n",
    "                # If all y values are 0, set to the smallest y value (0)\n",
    "                highest_y_values[x] = y_indices[0]\n",
    "        else:\n",
    "            # Handle the case when no edges are found in the column\n",
    "            if x > 0:\n",
    "                highest_y_values[x] = highest_y_values[x - 1]\n",
    "            else:\n",
    "                highest_y_values[x] = height\n",
    "\n",
    "    return highest_y_values\n",
    "\n",
    "def plot_highest_y_on_edges(edges, highest_y_values):\n",
    "    height, width = edges.shape\n",
    "    output_image = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    for x, y in enumerate(highest_y_values):\n",
    "        if y < height:  # Ensure we don't plot outside the image\n",
    "            cv2.line(output_image, (x, height), (x, y), (0, 255, 0), 1)  # Plot lines in green\n",
    "\n",
    "    return output_image\n",
    "\n",
    "def plot_only_highest_y_values(edges, highest_y_values):\n",
    "    height, width = edges.shape\n",
    "    output_image = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)  # Convert edges to a color image\n",
    "\n",
    "    for x, y in enumerate(highest_y_values):\n",
    "        if y < height:  # Ensure the Y value is within image bounds\n",
    "            cv2.circle(output_image, (x, y), 1, (0, 255, 0), -1)  # Draw a small green dot at the highest Y value\n",
    "\n",
    "    return output_image\n",
    "\n",
    "def plot_highest_y_on_original(original_image, highest_y_values, scale):\n",
    "    height, width = original_image.shape\n",
    "    output_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2BGR)  # Convert to color image for drawing\n",
    "\n",
    "    for x, y in enumerate(highest_y_values):\n",
    "        scaled_x = int(x * scale[1])\n",
    "        scaled_y = int(y * scale[0])\n",
    "        if scaled_y < height and scaled_y >= 0 and scaled_x < width and scaled_x >= 0:\n",
    "            cv2.circle(output_image, (scaled_x, scaled_y), 2, (0, 255, 0), -1)  # Draw a small green dot at the highest Y value\n",
    "\n",
    "    return output_image\n",
    "\n",
    "def detect_vertical_gaps(highest_y_values, gap_threshold=5):\n",
    "    gaps = []\n",
    "    start_end_points = []\n",
    "    for x in range(1, len(highest_y_values)):\n",
    "        if abs(highest_y_values[x] - highest_y_values[x - 1]) > gap_threshold:\n",
    "            start_end_points.append((x - 1, x))\n",
    "            gaps.append((x, (highest_y_values[x] + highest_y_values[x - 1]) // 2))\n",
    "    return gaps, start_end_points\n",
    "\n",
    "def plot_gaps(output_image, gaps):\n",
    "    for x, y in gaps:\n",
    "        cv2.circle(output_image, (x, y), 5, (255, 0, 0), 2)  # Draw a red circle around each gap\n",
    "\n",
    "    return output_image\n",
    "\n",
    "def calculate_tangent_vectors(highest_y_values, start_end_points):\n",
    "    tangent_vectors = []\n",
    "    for start, end in start_end_points:\n",
    "        start_point = (start, highest_y_values[start])\n",
    "        end_point = (end, highest_y_values[end])\n",
    "        vector = (end_point[0] - start_point[0], end_point[1] - start_point[1])\n",
    "        tangent_vectors.append((start_point, vector))\n",
    "    return tangent_vectors\n",
    "\n",
    "def remove_border_vectors(tangent_vectors, image_width, border_margin=30):\n",
    "    # Remove rising vectors close to the left border\n",
    "    tangent_vectors = [vec for vec in tangent_vectors if not (vec[0][0] < border_margin and vec[1][1] < 0)]\n",
    "\n",
    "    # Remove falling vectors close to the right border\n",
    "    tangent_vectors = [vec for vec in tangent_vectors if not (vec[0][0] > image_width - border_margin and vec[1][1] > 0)]\n",
    "\n",
    "    return tangent_vectors\n",
    "\n",
    "def plot_tangent_vectors(image, tangent_vectors):\n",
    "    for (start_x, start_y), (vec_x, vec_y) in tangent_vectors:\n",
    "        end_x = start_x + vec_x\n",
    "        end_y = start_y + vec_y\n",
    "        cv2.arrowedLine(image, (start_x, start_y), (end_x, end_y), (255, 0, 255), 2, tipLength=0.2)\n",
    "    return image\n",
    "\n",
    "def detect_single_rising_falling_patterns(tangent_vectors):\n",
    "    patterns = []\n",
    "    i = 0\n",
    "    while i < len(tangent_vectors) - 1:\n",
    "        if tangent_vectors[i][1][1] < 0 and tangent_vectors[i + 1][1][1] > 0:\n",
    "            patterns.append((tangent_vectors[i], tangent_vectors[i + 1]))\n",
    "            i += 2  # Move past this pattern\n",
    "        else:\n",
    "            i += 1\n",
    "    return patterns\n",
    "\n",
    "def draw_pattern_circles(image, patterns, unusual_spots, scale=(1.0, 1.0)):\n",
    "    for rising_vector, falling_vector in patterns:\n",
    "        x_coords = [rising_vector[0][0], falling_vector[0][0]]\n",
    "        y_coords = [rising_vector[0][1], falling_vector[0][1]]\n",
    "\n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "\n",
    "        center_x = int(((min_x + max_x) // 2) * scale[1])\n",
    "        center_y = int(((min_y + max_y) // 2) * scale[0])\n",
    "        radius = int(np.sqrt((max_x - min_x) ** 2 + (max_y - min_y) ** 2) / 2 * max(scale))\n",
    "\n",
    "        cv2.circle(image, (center_x, center_y), radius, (255, 0, 0), 2)\n",
    "\n",
    "    for x1, y1 in unusual_spots:\n",
    "        scaled_x = int(x1 * scale[1])\n",
    "        scaled_y = int(y1 * scale[0])\n",
    "        cv2.circle(image, (scaled_x, scaled_y), 5, (255, 255, 255), 2)\n",
    "\n",
    "    return image\n",
    "\n",
    "def detect_unusual_spots(highest_y_values, window_size=10, prominence_threshold=5, deviation_multiplier=2, slope_multiplier=2):\n",
    "    \"\"\"\n",
    "    Detects unusual spots in a given set of highest y-values.\n",
    "\n",
    "    Args:\n",
    "        highest_y_values (array-like): The highest y-values to analyze.\n",
    "        window_size (int, optional): The size of the window used for calculating average slopes. Defaults to 10.\n",
    "        prominence_threshold (int, optional): The prominence threshold used for detecting significant peaks and valleys. Defaults to 5.\n",
    "        deviation_multiplier (float, optional): The multiplier used for calculating the dynamic deviation threshold. Defaults to 2.\n",
    "        slope_multiplier (float, optional): The multiplier used for calculating the dynamic slope threshold. Defaults to 2.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples representing the filtered unusual spots. Each tuple contains the index and corresponding highest y-value.\n",
    "\n",
    "    \"\"\"\n",
    "    unusual_spots = []\n",
    "    slopes = np.diff(highest_y_values)  # Calculate the slopes\n",
    "\n",
    "    # Calculate dynamic deviation threshold\n",
    "    deviations = np.abs(np.diff(highest_y_values))\n",
    "    mean_deviation = np.mean(deviations)\n",
    "    std_deviation = np.std(deviations)\n",
    "    deviation_threshold = mean_deviation + deviation_multiplier * std_deviation\n",
    "\n",
    "    # Calculate dynamic slope threshold\n",
    "    mean_slope = np.mean(slopes)\n",
    "    std_slope = np.std(slopes)\n",
    "    slope_threshold = mean_slope + slope_multiplier * std_slope\n",
    "\n",
    "    print(f\"Deviation threshold: {deviation_threshold}\")\n",
    "    print(f\"Slope threshold: {slope_threshold}\")\n",
    "\n",
    "    # Calculate deviations and slopes\n",
    "    for x in range(1, len(highest_y_values)):\n",
    "        deviation = abs(highest_y_values[x] - highest_y_values[x - 1])\n",
    "        if deviation > deviation_threshold:\n",
    "            unusual_spots.append((x, highest_y_values[x]))\n",
    "        \n",
    "        if x >= window_size and x < len(slopes) - window_size:\n",
    "            avg_slope_before = np.mean(slopes[x-window_size:x])\n",
    "            avg_slope_after = np.mean(slopes[x:x+window_size])\n",
    "            if abs(avg_slope_before - avg_slope_after) > slope_threshold:\n",
    "                unusual_spots.append((x, highest_y_values[x]))\n",
    "\n",
    "    # Use find_peaks to detect significant peaks and valleys\n",
    "    peaks, _ = find_peaks(highest_y_values, prominence=prominence_threshold)\n",
    "    valleys, _ = find_peaks(-highest_y_values, prominence=prominence_threshold)\n",
    "    \n",
    "    for peak in peaks:\n",
    "        unusual_spots.append((peak, highest_y_values[peak]))\n",
    "    for valley in valleys:\n",
    "        unusual_spots.append((valley, highest_y_values[valley]))\n",
    "\n",
    "    # Filter to keep only the most significant spots\n",
    "    filtered_spots = []\n",
    "    last_added_spot = None\n",
    "    for spot in sorted(unusual_spots, key=lambda x: x[0]):\n",
    "        if last_added_spot is None or abs(spot[0] - last_added_spot[0]) > window_size:\n",
    "            filtered_spots.append(spot)\n",
    "            last_added_spot = spot\n",
    "\n",
    "    return filtered_spots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def concatenate_paths(base_path, filenames):\n",
    "    return [os.path.join(base_path, filename) for filename in filenames]\n",
    "\n",
    "def read_ground_truth_mask(filepath):\n",
    "    \"\"\"\n",
    "    Reads the ground truth mask image from the given filepath, converts it to a binary mask,\n",
    "    and draws the mask using matplotlib.\n",
    "    \"\"\"\n",
    "    mask = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        raise ValueError(f\"Could not read the image file at {filepath}\")\n",
    "    \n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Plotting the mask\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(binary_mask, cmap='gray')\n",
    "    plt.title('Ground Truth Mask')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return binary_mask\n",
    "\n",
    "def process_and_visualize_images(image_paths, gt_image_paths):\n",
    "    for image_path, gt_image_path in zip(image_paths, gt_image_paths):\n",
    "        # Preprocess the image\n",
    "        original_image, preprocessed_image, original_shape, crop_coords = preprocess_image(image_path)\n",
    "\n",
    "        # Apply binary masking\n",
    "        binary_image = binary_mask(preprocessed_image)\n",
    "\n",
    "        # Apply Canny edge detection\n",
    "        edges = canny_edge_detection(binary_image)\n",
    "\n",
    "        # Extract highest Y value edges\n",
    "        highest_y_values = extract_highest_y(edges)\n",
    "\n",
    "        # Plot highest Y values on the edges image\n",
    "        edges_with_highest_y = plot_highest_y_on_edges(edges, highest_y_values)\n",
    "\n",
    "        # Plot only highest Y values\n",
    "        highest_y_only = plot_only_highest_y_values(edges, highest_y_values)\n",
    "\n",
    "        # Plot only highest Y values with dots\n",
    "        highest_y_with_dots = plot_only_highest_y_values(edges, highest_y_values)\n",
    "\n",
    "        # Detect vertical gaps and get start-end points\n",
    "        gaps, start_end_points = detect_vertical_gaps(highest_y_values)\n",
    "\n",
    "        # Plot gaps on the highest Y values image\n",
    "        highest_y_with_gaps = plot_gaps(highest_y_only.copy(), gaps)\n",
    "\n",
    "        # Calculate tangent vectors\n",
    "        tangent_vectors = calculate_tangent_vectors(highest_y_values, start_end_points)\n",
    "        print(f\"Tangent vectors for {image_path}: {tangent_vectors}\")\n",
    "\n",
    "        # Remove border vectors\n",
    "        image_width = edges.shape[1]\n",
    "        tangent_vectors = remove_border_vectors(tangent_vectors, image_width)\n",
    "        print(f\"Tangent vectors after border removal for {image_path}: {tangent_vectors}\")\n",
    "\n",
    "        # Detect single rising and falling patterns\n",
    "        single_patterns = detect_single_rising_falling_patterns(tangent_vectors)\n",
    "        print(f\"Single rising and falling patterns for {image_path}: {single_patterns}\")\n",
    "\n",
    "        # Detect unusual spots\n",
    "        unusual_spots = detect_unusual_spots(highest_y_values)\n",
    "\n",
    "        # Draw circles around the detected patterns on the original image\n",
    "        scale = (original_shape[0] / 640, original_shape[1] / 640)\n",
    "        original_with_pattern_circles = draw_pattern_circles(original_image.copy(), single_patterns, unusual_spots, scale)\n",
    "\n",
    "        # Plot highest Y values with dots on the original image\n",
    "        original_with_dots = plot_highest_y_on_original(original_image.copy(), highest_y_values, scale)\n",
    "\n",
    "        # Plot tangent vectors on a separate image without circles\n",
    "        highest_y_with_vectors = plot_tangent_vectors(highest_y_only.copy(), tangent_vectors)\n",
    "\n",
    "        # Final image with patterns and unusual spots\n",
    "        final_image = draw_pattern_circles(highest_y_with_vectors, single_patterns, unusual_spots, scale)\n",
    "\n",
    "        # GroundTruth extract\n",
    "        gt_mask = read_ground_truth_mask(gt_image_path)\n",
    "\n",
    "        # Visualize the results\n",
    "        plt.figure(figsize=(40, 10))\n",
    "        plt.subplot(1, 10, 1)\n",
    "        plt.imshow(original_with_pattern_circles, cmap='gray')\n",
    "        plt.title('Result using Vertical Gaps indicator \\n + Outlier spot detection')\n",
    "\n",
    "        plt.subplot(1, 10, 2)\n",
    "        plt.imshow(original_with_dots, cmap='gray')\n",
    "        plt.title('ILM layer detection')\n",
    "\n",
    "       \n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Example usage\n",
    "\n",
    "test_filenames = [\n",
    "    'dr_test_1190_NV.jpg', 'img_02.jpeg', 'img_04.jpeg',\n",
    "    'img_05.jpeg', 'img_06.jpeg', 'img_07.jpeg',\n",
    "    'img_08.jpeg', 'img_09.jpeg', 'img_10.jpeg',\n",
    "    'img_11.jpeg', 'img_15.jpeg', 'img_16.jpeg',\n",
    "    'img_17.jpeg', 'img_18.jpeg', 'img_19.jpeg',\n",
    "    'img_21.jpeg', 'img_23.jpeg', 'img_24.jpeg',\n",
    "    'img_25.jpeg', 'img_a_NV.jpeg','img_b_NV.jpeg',\n",
    "    'img_c_NV.jpeg','img_d_NV.jpeg', 'img_e_NV.jpeg'\n",
    "]\n",
    "gt_filenames = [\n",
    "    'dr_test_1190_NV (1)_NV.png', 'img_02 (1)_NV.png', 'img_04_NV.png',\n",
    "    'img_05_NV.png', 'img_06_NV.png', 'img_07_NV.png',\n",
    "    'img_08_NV.png', 'img_09 (1)_NV.png', 'img_10_NV.png',\n",
    "    'img_11 (1)_NV.png', 'img_15_NV.png', 'img_16_NV.png',\n",
    "    'img_17_NV.png', 'img_18_NV.png', 'img_19_NV.png',\n",
    "    'img_21 (1)_NV.png', 'img_23_NV.png', 'img_24_NV.png',\n",
    "    'img_25_NV.png', 'img_a_NV.png','img_b_NV.png' \n",
    "    ,'img_c_NV.png' ,'img_d_NV.png', 'img_e_NV.png'\n",
    "]\n",
    "\n",
    "test_base_path = 'DATA_OCT'\n",
    "\n",
    "gt_base_path = 'NV_GT'\n",
    "\n",
    "test_image_paths = concatenate_paths(test_base_path, test_filenames)\n",
    "gt_image_paths = concatenate_paths(gt_base_path, gt_filenames)\n",
    "\n",
    "process_and_visualize_images(test_image_paths, gt_image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.60\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image at path {image_path} not found.\")\n",
    "    \n",
    "    # Replace white pixels with black\n",
    "    image[image > 250] = 0\n",
    "    \n",
    "    # Detect and remove white borders\n",
    "    _, thresh = cv2.threshold(image, 240, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    non_white_pixels = np.where(thresh < 240)\n",
    "\n",
    "    if non_white_pixels[0].size == 0 or non_white_pixels[1].size == 0:\n",
    "        raise ValueError(\"No relevant pixels found in the image.\")\n",
    "\n",
    "    # Crop image to non-white pixels\n",
    "    y_min, y_max = np.min(non_white_pixels[0]), np.max(non_white_pixels[0])\n",
    "    x_min, x_max = np.min(non_white_pixels[1]), np.max(non_white_pixels[1])\n",
    "    image = image[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    # Apply noise reduction\n",
    "    image_denoised = cv2.fastNlMeansDenoising(\n",
    "        cv2.bilateralFilter(\n",
    "            cv2.medianBlur(image, 5), 9, 75, 75\n",
    "        ), h=30\n",
    "    )\n",
    "\n",
    "    # Apply wavelet denoising\n",
    "    coeffs = pywt.wavedec2(image_denoised, 'db1', level=2)\n",
    "    coeffs[1:] = [tuple(pywt.threshold(i, value=10, mode='soft') for i in level) for level in coeffs[1:]]\n",
    "    image_wavelet_denoised = pywt.waverec2(coeffs, 'db1')\n",
    "\n",
    "    # Normalize and expand dimensions\n",
    "    image_wavelet_denoised = np.expand_dims(image_wavelet_denoised, axis=(0, -1)).astype('float32') / 255.0\n",
    "    return image, image_wavelet_denoised\n",
    "\n",
    "def binary_mask(image):\n",
    "    # Convert to uint8, apply Gaussian blur, and binary thresholding\n",
    "    image_uint8 = (image * 255).astype(np.uint8).squeeze()\n",
    "    blurred_image = cv2.GaussianBlur(image_uint8, (5, 5), 0)\n",
    "    _, binary_image = cv2.threshold(blurred_image, 62.5, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_image\n",
    "\n",
    "def canny_edge_detection(image):\n",
    "    return cv2.Canny(image, 100, 200)\n",
    "\n",
    "def extract_highest_y(edges):\n",
    "    height, width = edges.shape\n",
    "    highest_y_values = np.full(width, height)  # Initialize with bottom of image\n",
    "\n",
    "    for x in range(width):\n",
    "        column = edges[:, x]\n",
    "        y_indices = np.where(column > 0)[0]\n",
    "        if y_indices.size > 0:\n",
    "            highest_y_values[x] = y_indices.min()\n",
    "    \n",
    "    return highest_y_values\n",
    "\n",
    "def plot_highest_y_on_edges(edges, highest_y_values, base_thickness=8):\n",
    "    # Create an output image with the same dimensions as the input edges\n",
    "    output_image = np.zeros_like(edges)\n",
    "    \n",
    "    # Calculate dynamic thickness based on image height\n",
    "    image_height, _ = edges.shape\n",
    "    dynamic_thickness = int(base_thickness * (image_height / 640))  # Scale thickness based on image height\n",
    "\n",
    "    # Iterate through each x-coordinate\n",
    "    for x, y in enumerate(highest_y_values):\n",
    "        if y < edges.shape[0]:\n",
    "            # Draw a thicker line by using a thicker line width\n",
    "            start_y = max(0, y - dynamic_thickness // 2)\n",
    "            end_y = min(edges.shape[0], y + dynamic_thickness // 2 + 1)\n",
    "            output_image[start_y:end_y, x] = 255\n",
    "    \n",
    "    return output_image\n",
    "\n",
    "\n",
    "\n",
    "def concatenate_paths(base_path, filenames):\n",
    "    return [os.path.join(base_path, filename) for filename in filenames]\n",
    "\n",
    "def pad_to_size(image, target_shape):\n",
    "    target_height, target_width = target_shape\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # Create a canvas with target size and place the image in the center\n",
    "    padded_image = np.zeros((target_height, target_width), dtype=np.uint8)\n",
    "    top = (target_height - height) // 2\n",
    "    left = (target_width - width) // 2\n",
    "    padded_image[top:top + height, left:left + width] = image\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "def calculate_f1_score(ground_truth_image, predicted_image):\n",
    "    _, ground_truth_binary = cv2.threshold(ground_truth_image, 127, 255, cv2.THRESH_BINARY)\n",
    "    _, predicted_binary = cv2.threshold(predicted_image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Visualize for debugging\n",
    "    # fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    # axs[0].imshow(ground_truth_binary, cmap='gray')\n",
    "    # axs[0].set_title('Ground Truth Binary')\n",
    "    # axs[0].axis('on')\n",
    "\n",
    "    # axs[1].imshow(predicted_binary, cmap='gray')\n",
    "    # axs[1].set_title('Predicted Binary')\n",
    "    # axs[1].axis('on')\n",
    "\n",
    "    # axs[2].imshow(predicted_image, cmap='gray')\n",
    "    # axs[2].set_title('Predicted Original')\n",
    "    # axs[2].axis('on')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return f1_score(ground_truth_binary.flatten(), predicted_binary.flatten(), pos_label=255, average='binary')\n",
    "\n",
    "def process_and_visualize_images(test_image_paths, eval_image_paths):\n",
    "    f1_scores = []\n",
    "\n",
    "    for test_image_path, eval_image_path in zip(test_image_paths, eval_image_paths):\n",
    "        # Preprocess the image\n",
    "        original_image, preprocessed_image = preprocess_image(test_image_path)\n",
    "        binary_image = binary_mask(preprocessed_image)\n",
    "        edges = canny_edge_detection(binary_image)\n",
    "        highest_y_values = extract_highest_y(edges)\n",
    "        highest_y_image = plot_highest_y_on_edges(edges, highest_y_values)\n",
    "        \n",
    "\n",
    "        # Load ground truth image\n",
    "        ground_truth_image = cv2.imread(eval_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if ground_truth_image is None:\n",
    "            raise FileNotFoundError(f\"Ground truth image at path {eval_image_path} not found.\")\n",
    "\n",
    "        # Pad images to ensure the same size\n",
    "        max_height = max(ground_truth_image.shape[0], highest_y_image.shape[0])\n",
    "        max_width = max(ground_truth_image.shape[1], highest_y_image.shape[1])\n",
    "\n",
    "        ground_truth_padded = pad_to_size(ground_truth_image, (max_height, max_width))\n",
    "        top_line_padded = pad_to_size(highest_y_image, (max_height, max_width))\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = calculate_f1_score(ground_truth_padded, top_line_padded)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Plot results\n",
    "        # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[0].imshow(top_line_padded, cmap='gray')\n",
    "        # axs[0].set_title('Top Line')\n",
    "        # axs[0].text(10, 20, f'F1: {f1:.2f}', color='red', fontsize=12, bbox=dict(facecolor='white', alpha=0.8))\n",
    "        # axs[0].axis('on')\n",
    "\n",
    "        # axs[1].imshow(ground_truth_padded, cmap='gray')\n",
    "        # axs[1].set_title('Ground Truth')\n",
    "        # axs[1].axis('on')\n",
    "\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        # axs[2].imshow(highest_y_image, cmap='gray')\n",
    "        # axs[2].set_title('Highest Y Values')\n",
    "        # axs[2].axis('on')\n",
    "\n",
    "\n",
    "    # Print the average F1 score\n",
    "    print(f\"Average F1 Score: {np.mean(f1_scores):.2f}\")\n",
    "\n",
    "# Example usage\n",
    "test_base_path = 'DATA_OCT'\n",
    "eval_base_path1 = 'BOOM_ILM'\n",
    "\n",
    "test_filenames = [\n",
    "    'dr_test_1190_NV.jpg', 'img_02.jpeg', 'img_04.jpeg',\n",
    "    'img_05.jpeg', 'img_06.jpeg', 'img_07.jpeg',\n",
    "    'img_08.jpeg', 'img_09.jpeg', 'img_10.jpeg',\n",
    "    'img_11.jpeg', 'img_15.jpeg', 'img_16.jpeg',\n",
    "    'img_17.jpeg', 'img_18.jpeg', 'img_19.jpeg',\n",
    "    'img_21.jpeg', 'img_23.jpeg', 'img_24.jpeg',\n",
    "    'img_25.jpeg'\n",
    "]\n",
    "\n",
    "eval_filenamesBoom = [\n",
    "    'dr_test_1190_NV.png', 'img_02.png', 'img_04.png',\n",
    "    'img_05.png', 'img_06.png', 'img_07.png',\n",
    "    'img_08.png', 'img_09 (1).PNG', 'img_10.png',\n",
    "    'img_11.png', 'img_15.png', 'img_16.png',\n",
    "    'img_17.png', 'img_18.png', 'img_19.png',\n",
    "    'img_21.png', 'img_23.png', 'img_24.png',\n",
    "    'img_25.png'\n",
    "]\n",
    "\n",
    "test_image_paths = concatenate_paths(test_base_path, test_filenames)\n",
    "eval_image_paths1 = concatenate_paths(eval_base_path1, eval_filenamesBoom)\n",
    "\n",
    "process_and_visualize_images(test_image_paths, eval_image_paths1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
